/usr/bin/c++ -g CMakeFiles/self_attention_example.dir/self_attention_example.cpp.o CMakeFiles/self_attention_example.dir/cmake_device_link.o -o self_attention_example   -L/usr/local/cuda-12.5/targets/x86_64-linux/lib/stubs  -L/usr/local/cuda-12.5/targets/x86_64-linux/lib  -Wl,-rpath,/usr/local/cuda-12.5/lib64:/usr/lib/wsl/lib -lcudart -lcudadevrt ../../src/layers/libllama_self_attention.a -lcudadevrt ../../src/kernels/libqkv_bias_and_rope.a ../../src/kernels/libconcat_past_kv.a ../../src/kernels/liblinear.a -lcudart ../../src/kernels/libcublasWrapper.a /usr/local/cuda-12.5/lib64/libcublas.so /usr/lib/wsl/lib/libcuda.so -lcublas ../../src/kernels/libtranspose_and_remove_padding.a ../../src/kernels/librepeat_kv.a ../../src/kernels/libscale_and_mask_and_softmax.a ../../src/kernels/libdecoder_self_attention.a -lcudadevrt -lcudart_static -lrt -lpthread -ldl 
