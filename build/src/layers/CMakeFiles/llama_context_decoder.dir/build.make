# CMAKE generated file: DO NOT EDIT!
# Generated by "Unix Makefiles" Generator, CMake Version 3.22

# Delete rule output on recipe failure.
.DELETE_ON_ERROR:

#=============================================================================
# Special targets provided by cmake.

# Disable implicit rules so canonical targets will work.
.SUFFIXES:

# Disable VCS-based implicit rules.
% : %,v

# Disable VCS-based implicit rules.
% : RCS/%

# Disable VCS-based implicit rules.
% : RCS/%,v

# Disable VCS-based implicit rules.
% : SCCS/s.%

# Disable VCS-based implicit rules.
% : s.%

.SUFFIXES: .hpux_make_needs_suffix_list

# Command-line flag to silence nested $(MAKE).
$(VERBOSE)MAKESILENT = -s

#Suppress display of executed commands.
$(VERBOSE).SILENT:

# A target that is always out of date.
cmake_force:
.PHONY : cmake_force

#=============================================================================
# Set environment variables for the build.

# The shell in which to execute make rules.
SHELL = /bin/sh

# The CMake executable.
CMAKE_COMMAND = /usr/bin/cmake

# The command to remove a file.
RM = /usr/bin/cmake -E rm -f

# Escaping for special characters.
EQUALS = =

# The top-level source directory on which CMake was run.
CMAKE_SOURCE_DIR = "/home/tourist/AI-HPC Projects/llm_inference_engine"

# The top-level build directory on which CMake was run.
CMAKE_BINARY_DIR = "/home/tourist/AI-HPC Projects/llm_inference_engine/build"

# Include any dependencies generated for this target.
include src/layers/CMakeFiles/llama_context_decoder.dir/depend.make
# Include any dependencies generated by the compiler for this target.
include src/layers/CMakeFiles/llama_context_decoder.dir/compiler_depend.make

# Include the progress variables for this target.
include src/layers/CMakeFiles/llama_context_decoder.dir/progress.make

# Include the compile flags for this target's objects.
include src/layers/CMakeFiles/llama_context_decoder.dir/flags.make

src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o: src/layers/CMakeFiles/llama_context_decoder.dir/flags.make
src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o: ../src/layers/context_decoder.cpp
src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o: src/layers/CMakeFiles/llama_context_decoder.dir/compiler_depend.ts
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --green --progress-dir="/home/tourist/AI-HPC Projects/llm_inference_engine/build/CMakeFiles" --progress-num=$(CMAKE_PROGRESS_1) "Building CXX object src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o"
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -MD -MT src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o -MF CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o.d -o CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o -c "/home/tourist/AI-HPC Projects/llm_inference_engine/src/layers/context_decoder.cpp"

src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.i: cmake_force
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --green "Preprocessing CXX source to CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.i"
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -E "/home/tourist/AI-HPC Projects/llm_inference_engine/src/layers/context_decoder.cpp" > CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.i

src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.s: cmake_force
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --green "Compiling CXX source to assembly CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.s"
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && /usr/bin/c++ $(CXX_DEFINES) $(CXX_INCLUDES) $(CXX_FLAGS) -S "/home/tourist/AI-HPC Projects/llm_inference_engine/src/layers/context_decoder.cpp" -o CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.s

# Object files for target llama_context_decoder
llama_context_decoder_OBJECTS = \
"CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o"

# External object files for target llama_context_decoder
llama_context_decoder_EXTERNAL_OBJECTS =

src/layers/CMakeFiles/llama_context_decoder.dir/cmake_device_link.o: src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o
src/layers/CMakeFiles/llama_context_decoder.dir/cmake_device_link.o: src/layers/CMakeFiles/llama_context_decoder.dir/build.make
src/layers/CMakeFiles/llama_context_decoder.dir/cmake_device_link.o: src/layers/CMakeFiles/llama_context_decoder.dir/dlink.txt
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --green --bold --progress-dir="/home/tourist/AI-HPC Projects/llm_inference_engine/build/CMakeFiles" --progress-num=$(CMAKE_PROGRESS_2) "Linking CUDA device code CMakeFiles/llama_context_decoder.dir/cmake_device_link.o"
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && $(CMAKE_COMMAND) -E cmake_link_script CMakeFiles/llama_context_decoder.dir/dlink.txt --verbose=$(VERBOSE)

# Rule to build all files generated by this target.
src/layers/CMakeFiles/llama_context_decoder.dir/build: src/layers/CMakeFiles/llama_context_decoder.dir/cmake_device_link.o
.PHONY : src/layers/CMakeFiles/llama_context_decoder.dir/build

# Object files for target llama_context_decoder
llama_context_decoder_OBJECTS = \
"CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o"

# External object files for target llama_context_decoder
llama_context_decoder_EXTERNAL_OBJECTS =

src/layers/libllama_context_decoder.a: src/layers/CMakeFiles/llama_context_decoder.dir/context_decoder.cpp.o
src/layers/libllama_context_decoder.a: src/layers/CMakeFiles/llama_context_decoder.dir/build.make
src/layers/libllama_context_decoder.a: src/layers/CMakeFiles/llama_context_decoder.dir/cmake_device_link.o
src/layers/libllama_context_decoder.a: src/layers/CMakeFiles/llama_context_decoder.dir/link.txt
	@$(CMAKE_COMMAND) -E cmake_echo_color --switch=$(COLOR) --green --bold --progress-dir="/home/tourist/AI-HPC Projects/llm_inference_engine/build/CMakeFiles" --progress-num=$(CMAKE_PROGRESS_3) "Linking CXX static library libllama_context_decoder.a"
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && $(CMAKE_COMMAND) -P CMakeFiles/llama_context_decoder.dir/cmake_clean_target.cmake
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && $(CMAKE_COMMAND) -E cmake_link_script CMakeFiles/llama_context_decoder.dir/link.txt --verbose=$(VERBOSE)

# Rule to build all files generated by this target.
src/layers/CMakeFiles/llama_context_decoder.dir/build: src/layers/libllama_context_decoder.a
.PHONY : src/layers/CMakeFiles/llama_context_decoder.dir/build

src/layers/CMakeFiles/llama_context_decoder.dir/clean:
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" && $(CMAKE_COMMAND) -P CMakeFiles/llama_context_decoder.dir/cmake_clean.cmake
.PHONY : src/layers/CMakeFiles/llama_context_decoder.dir/clean

src/layers/CMakeFiles/llama_context_decoder.dir/depend:
	cd "/home/tourist/AI-HPC Projects/llm_inference_engine/build" && $(CMAKE_COMMAND) -E cmake_depends "Unix Makefiles" "/home/tourist/AI-HPC Projects/llm_inference_engine" "/home/tourist/AI-HPC Projects/llm_inference_engine/src/layers" "/home/tourist/AI-HPC Projects/llm_inference_engine/build" "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers" "/home/tourist/AI-HPC Projects/llm_inference_engine/build/src/layers/CMakeFiles/llama_context_decoder.dir/DependInfo.cmake" --color=$(COLOR)
.PHONY : src/layers/CMakeFiles/llama_context_decoder.dir/depend

