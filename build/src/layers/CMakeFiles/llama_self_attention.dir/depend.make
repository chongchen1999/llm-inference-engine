# Empty dependencies file for llama_self_attention.
# This may be replaced when dependencies are built.
